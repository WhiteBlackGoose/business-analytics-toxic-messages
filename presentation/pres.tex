\documentclass{beamer}

\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{listings}
\graphicspath{ {./pics/} }

\title{Toxic Message Detection}
\subtitle{Machine learning}
\date{2023-06-13}
\institute{HSE University}

\usetheme{Boadilla}
\begin{document}
  \frame {
    \titlepage
  }
  \frame {
    \frametitle{Primary preprocessing}
\begin{itemize}
\item Tokenize
\item Drop stop words
\end{itemize}
(file: preprocess.py)
  }
  \frame {
    \frametitle{Frequency preprocessing: Bayesian analysis}
\begin{block}{}
  \begin{center}
  \vspace{5pt}
  How many times is this word encounted in toxic and regular messages?
  \vspace{5pt}
  \end{center}
\end{block}
\begin{block}{}
  \begin{center}
  \vspace{5pt}
  $\implies$ how much does the given word affect the probability, that the message is toxic?
  \vspace{5pt}
  \end{center}
\end{block}
\begin{block}{}
  \begin{center}
  \vspace{5pt}
    Frequency dictionary contains 150 words with the highest effect
  \vspace{5pt}
  \end{center}
\end{block}
  }
  \frame {
    \frametitle{Frequency preprocessing: formula}
\begin{itemize}
  \item $T$ - total number of toxic messages
  \item $t$ - number of times this word appears in toxic messages
  \item $T^c$ and $t^c$ are their respective complements
\end{itemize}
\begin{block}{}
  \begin{center}
\[
effect = \left(\frac{t^c}{T^c}-\frac{t}{T}\right)\frac{T+T^c}{t+t^c}
\]
  \vspace{5pt}
  \end{center}
\end{block}
(file: preprocess\_frequency.py)
  }
  \frame {
    \frametitle{RNN Preprocessing: Words}
\begin{itemize}
  \item glove.840B.300d words semantic database
  \item Turn each tweet into a list of vectors of length 300
\end{itemize}
(file: preprocess\_rnn.py)
  }
  \frame {
    \frametitle{RNN Preprocessing: Training}
\begin{itemize}
  \item Supply encoder initial state and, sequentially, input tokens
  \item Obtain the final state
  \item Check every decoder's output against the expected input
  \item Update weights
\end{itemize}
The output is a 100d vector.
(file: preprocess\_rnn.py, rnn.py)
  }
  \frame {
    \frametitle{Fit models: Frequency Dictionary}
\begin{itemize}
  \item Input: vector of 150 floats. Each float represents how many the given message contains words from the 150 most influential words. 
  \item Output: class 0 or 1
\end{itemize}
  }
  \frame {
    \frametitle{Fit models: RNN}
\begin{itemize}
  \item Input: vector of 100 floats, which correspond to the semantics of the message
  \item Output: class 0 or 1
\end{itemize}
  }
  \frame {
    \frametitle{Models fitting and comparison}
\begin{center}
\begin{tabular}{lcccc}
Model             & Train Acc & Test Acc & Train $f_1$ & Test $f_1$\\
Freq SVM           & 0.9766    & 0.9568   & 0.4392    & 0.2447   \\
RNN AdaBoost       & 0.9694    & 0.9614   & --        & --       \\
Freq LDA           & --        & --       & --        & 0.2400   \\
RNN Random Forest  & 0.9863    & 0.6000   & --        & 0.4440   \\
Freq KNN           & 0.9450    & 0.9434   & 0.3460    & 0.3090   \\
RNN Log Regression & 0.9700    & 0.9270   & --        & --       \\
Freq KNN Balanced  & 0.5270    & 0.5220   & 0.6590    & 0.6550   \\
Freq SVM Balanced  & 0.6919    & 0.6767   & 0.5939    & 0.5765   \\
Freq LDA Balanced  & 0.7930    & 0.7393   & --        & 0.6710   \\
\end{tabular}
\end{center}
  }
\end{document}
