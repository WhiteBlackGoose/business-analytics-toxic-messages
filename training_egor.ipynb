{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba1c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import proc\n",
    "import freq\n",
    "from freq import read_kw, word_list2freq_dict\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "reload(freq)\n",
    "\n",
    "kw = read_kw()\n",
    "\n",
    "train = pd.read_csv(\"./train.csv\")[['target', 'comment_text']]\n",
    "train['toxic'] = 1 * (train['target'] > 0.5)\n",
    "\n",
    "train_toxic = train[train['toxic'] == 1]\n",
    "train_not_toxic = train[train['toxic'] == 0].sample(len(train_toxic))\n",
    "train = pd.concat([train_toxic, train_not_toxic]).sample(len(train_toxic) * 2)\n",
    "\n",
    "def comment_text_to_vec(comment_text):\n",
    "    p = proc(comment_text, [1, 2])\n",
    "    return word_list2freq_dict(kw, p)\n",
    "\n",
    "train[\"comment\"] = train['comment_text'].apply(comment_text_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87813df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[\"comment\"], train[\"toxic\"])\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = LinearDiscriminantAnalysis()\n",
    "m1.fit(X_train, y_train)\n",
    "pred = m1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21728ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7488151658767772"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3275076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6824644549763034"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca61d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "print(confusion_matrix(pred, y_test))\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85023385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6635071090047393"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = QuadraticDiscriminantAnalysis()\n",
    "m2.fit(X_train, y_train)\n",
    "m2.score(X_train, y_train)\n",
    "m2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc752d",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2edf20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4391.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [34:31<00:00, 20.72s/it]\n"
     ]
    }
   ],
   "source": [
    "from rnn import Encoder\n",
    "from preprocess import proc\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "encoder = Encoder(300, 300, 100, 1)\n",
    "encoder.load_weights(\"encoder.weights\")\n",
    "\n",
    "w2v_dict = dict()\n",
    "f = open(\"./glove.840B.300d.txt\", \"rt\", encoding='utf8')\n",
    "for i in tqdm(range(10000)):\n",
    "    line = f.readline()\n",
    "    els = line.split()\n",
    "    token = els[0]\n",
    "    try:\n",
    "        value = tf.convert_to_tensor(list(map(float, els[1:])), dtype=tf.float32)\n",
    "    except:\n",
    "        break\n",
    "    w2v_dict[token] = value\n",
    "f.close()\n",
    "\n",
    "def comment_text_to_vec(comment_text):\n",
    "    p = proc(comment_text, [1, 2])\n",
    "    tweet = []\n",
    "    for word in p:\n",
    "        if word in w2v_dict:\n",
    "            tweet.append(w2v_dict[word])\n",
    "    if len(tweet) == 0:\n",
    "        return None\n",
    "    tweet = tf.stack(tweet)\n",
    "    tweet = tf.expand_dims(tweet, axis=1)\n",
    "    tweet = tf.expand_dims(tweet, axis=3)\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    for word in tweet:\n",
    "        out_t, enc_hidden = encoder(word, enc_hidden)\n",
    "    return enc_hidden[0].numpy()\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"./train.csv\")[['target', 'comment_text']]\n",
    "train['toxic'] = 1 * (train['target'] > 0.5)\n",
    "\n",
    "train_toxic = train[train['toxic'] == 1]\n",
    "train_not_toxic = train[train['toxic'] == 0].sample(len(train_toxic))\n",
    "train = pd.concat([train_toxic, train_not_toxic]).sample(len(train_toxic) * 2)\n",
    "\n",
    "\n",
    "print(\"Training\")\n",
    "X, y = [], []\n",
    "for Xrow, yrow in tqdm(list(zip(train['comment_text'], train[\"toxic\"]))[:100]):\n",
    "    v = comment_text_to_vec(Xrow)\n",
    "    if v is not None:\n",
    "        X.append(v)\n",
    "        y.append(yrow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc85b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.9863013698630136\n",
      "Test error: 0.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.stack(X)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "m = RandomForestClassifier()\n",
    "m.fit(X_train, y_train)\n",
    "print(\"Train error:\", m.score(X_train, y_train))\n",
    "print(\"Test error:\", m.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79715c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5cb0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  5]\n",
      " [ 5  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.688     0.688     0.688        16\n",
      "           1      0.444     0.444     0.444         9\n",
      "\n",
      "    accuracy                          0.600        25\n",
      "   macro avg      0.566     0.566     0.566        25\n",
      "weighted avg      0.600     0.600     0.600        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred_rf, y_test))\n",
    "print(classification_report(y_test, pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572287a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
